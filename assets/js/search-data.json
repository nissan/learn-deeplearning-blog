{
  
    
        "post0": {
            "title": "Testing out Javascript inside a notebook",
            "content": "First attempt - Using Pixiedust and Pixiedust_node . First we&#39;re going to borrow from a notebook IBM published on getting this approach up and running . # install or upgrade the packages # restart the kernel to pick up the latest version !pip install pixiedust --upgrade !pip install pixiedust_node --upgrade . Requirement already up-to-date: pixiedust in c: tools anaconda3 envs fastai2 lib site-packages (1.1.18) Requirement already satisfied, skipping upgrade: colour in c: tools anaconda3 envs fastai2 lib site-packages (from pixiedust) (0.1.5) Requirement already satisfied, skipping upgrade: requests in c: tools anaconda3 envs fastai2 lib site-packages (from pixiedust) (2.23.0) Requirement already satisfied, skipping upgrade: geojson in c: tools anaconda3 envs fastai2 lib site-packages (from pixiedust) (2.5.0) Requirement already satisfied, skipping upgrade: markdown in c: tools anaconda3 envs fastai2 lib site-packages (from pixiedust) (3.2.1) Requirement already satisfied, skipping upgrade: mpld3 in c: tools anaconda3 envs fastai2 lib site-packages (from pixiedust) (0.3) Requirement already satisfied, skipping upgrade: lxml in c: tools anaconda3 envs fastai2 lib site-packages (from pixiedust) (4.5.0) Requirement already satisfied, skipping upgrade: astunparse in c: tools anaconda3 envs fastai2 lib site-packages (from pixiedust) (1.6.3) Requirement already satisfied, skipping upgrade: idna&lt;3,&gt;=2.5 in c: tools anaconda3 envs fastai2 lib site-packages (from requests-&gt;pixiedust) (2.9) Requirement already satisfied, skipping upgrade: chardet&lt;4,&gt;=3.0.2 in c: tools anaconda3 envs fastai2 lib site-packages (from requests-&gt;pixiedust) (3.0.4) Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in c: tools anaconda3 envs fastai2 lib site-packages (from requests-&gt;pixiedust) (1.25.8) Requirement already satisfied, skipping upgrade: certifi&gt;=2017.4.17 in c: tools anaconda3 envs fastai2 lib site-packages (from requests-&gt;pixiedust) (2019.11.28) Requirement already satisfied, skipping upgrade: setuptools&gt;=36 in c: tools anaconda3 envs fastai2 lib site-packages (from markdown-&gt;pixiedust) (46.1.1.post20200323) Requirement already satisfied, skipping upgrade: six&lt;2.0,&gt;=1.6.1 in c: tools anaconda3 envs fastai2 lib site-packages (from astunparse-&gt;pixiedust) (1.14.0) Requirement already satisfied, skipping upgrade: wheel&lt;1.0,&gt;=0.23.0 in c: tools anaconda3 envs fastai2 lib site-packages (from astunparse-&gt;pixiedust) (0.34.2) Requirement already up-to-date: pixiedust_node in c: tools anaconda3 envs fastai2 lib site-packages (0.2.5) Requirement already satisfied, skipping upgrade: pixiedust in c: tools anaconda3 envs fastai2 lib site-packages (from pixiedust_node) (1.1.18) Requirement already satisfied, skipping upgrade: pandas in c: tools anaconda3 envs fastai2 lib site-packages (from pixiedust_node) (1.0.3) Requirement already satisfied, skipping upgrade: ipython in c: tools anaconda3 envs fastai2 lib site-packages (from pixiedust_node) (7.13.0) Requirement already satisfied, skipping upgrade: lxml in c: tools anaconda3 envs fastai2 lib site-packages (from pixiedust-&gt;pixiedust_node) (4.5.0) Requirement already satisfied, skipping upgrade: colour in c: tools anaconda3 envs fastai2 lib site-packages (from pixiedust-&gt;pixiedust_node) (0.1.5) Requirement already satisfied, skipping upgrade: geojson in c: tools anaconda3 envs fastai2 lib site-packages (from pixiedust-&gt;pixiedust_node) (2.5.0) Requirement already satisfied, skipping upgrade: astunparse in c: tools anaconda3 envs fastai2 lib site-packages (from pixiedust-&gt;pixiedust_node) (1.6.3) Requirement already satisfied, skipping upgrade: markdown in c: tools anaconda3 envs fastai2 lib site-packages (from pixiedust-&gt;pixiedust_node) (3.2.1) Requirement already satisfied, skipping upgrade: mpld3 in c: tools anaconda3 envs fastai2 lib site-packages (from pixiedust-&gt;pixiedust_node) (0.3) Requirement already satisfied, skipping upgrade: requests in c: tools anaconda3 envs fastai2 lib site-packages (from pixiedust-&gt;pixiedust_node) (2.23.0) Requirement already satisfied, skipping upgrade: pytz&gt;=2017.2 in c: tools anaconda3 envs fastai2 lib site-packages (from pandas-&gt;pixiedust_node) (2019.3) Requirement already satisfied, skipping upgrade: numpy&gt;=1.13.3 in c: tools anaconda3 envs fastai2 lib site-packages (from pandas-&gt;pixiedust_node) (1.18.1) Requirement already satisfied, skipping upgrade: python-dateutil&gt;=2.6.1 in c: tools anaconda3 envs fastai2 lib site-packages (from pandas-&gt;pixiedust_node) (2.8.1) Requirement already satisfied, skipping upgrade: pickleshare in c: tools anaconda3 envs fastai2 lib site-packages (from ipython-&gt;pixiedust_node) (0.7.5) Requirement already satisfied, skipping upgrade: decorator in c: tools anaconda3 envs fastai2 lib site-packages (from ipython-&gt;pixiedust_node) (4.4.2) Requirement already satisfied, skipping upgrade: prompt-toolkit!=3.0.0,!=3.0.1,&lt;3.1.0,&gt;=2.0.0 in c: tools anaconda3 envs fastai2 lib site-packages (from ipython-&gt;pixiedust_node) (3.0.4) Requirement already satisfied, skipping upgrade: pygments in c: tools anaconda3 envs fastai2 lib site-packages (from ipython-&gt;pixiedust_node) (2.6.1) Requirement already satisfied, skipping upgrade: backcall in c: tools anaconda3 envs fastai2 lib site-packages (from ipython-&gt;pixiedust_node) (0.1.0) Requirement already satisfied, skipping upgrade: colorama; sys_platform == &#34;win32&#34; in c: tools anaconda3 envs fastai2 lib site-packages (from ipython-&gt;pixiedust_node) (0.4.3) Requirement already satisfied, skipping upgrade: setuptools&gt;=18.5 in c: tools anaconda3 envs fastai2 lib site-packages (from ipython-&gt;pixiedust_node) (46.1.1.post20200323) Requirement already satisfied, skipping upgrade: jedi&gt;=0.10 in c: tools anaconda3 envs fastai2 lib site-packages (from ipython-&gt;pixiedust_node) (0.16.0) Requirement already satisfied, skipping upgrade: traitlets&gt;=4.2 in c: tools anaconda3 envs fastai2 lib site-packages (from ipython-&gt;pixiedust_node) (4.3.3) Requirement already satisfied, skipping upgrade: wheel&lt;1.0,&gt;=0.23.0 in c: tools anaconda3 envs fastai2 lib site-packages (from astunparse-&gt;pixiedust-&gt;pixiedust_node) (0.34.2) Requirement already satisfied, skipping upgrade: six&lt;2.0,&gt;=1.6.1 in c: tools anaconda3 envs fastai2 lib site-packages (from astunparse-&gt;pixiedust-&gt;pixiedust_node) (1.14.0) Requirement already satisfied, skipping upgrade: idna&lt;3,&gt;=2.5 in c: tools anaconda3 envs fastai2 lib site-packages (from requests-&gt;pixiedust-&gt;pixiedust_node) (2.9) Requirement already satisfied, skipping upgrade: chardet&lt;4,&gt;=3.0.2 in c: tools anaconda3 envs fastai2 lib site-packages (from requests-&gt;pixiedust-&gt;pixiedust_node) (3.0.4) Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in c: tools anaconda3 envs fastai2 lib site-packages (from requests-&gt;pixiedust-&gt;pixiedust_node) (1.25.8) Requirement already satisfied, skipping upgrade: certifi&gt;=2017.4.17 in c: tools anaconda3 envs fastai2 lib site-packages (from requests-&gt;pixiedust-&gt;pixiedust_node) (2019.11.28) Requirement already satisfied, skipping upgrade: wcwidth in c: tools anaconda3 envs fastai2 lib site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,&lt;3.1.0,&gt;=2.0.0-&gt;ipython-&gt;pixiedust_node) (0.1.8) Requirement already satisfied, skipping upgrade: parso&gt;=0.5.2 in c: tools anaconda3 envs fastai2 lib site-packages (from jedi&gt;=0.10-&gt;ipython-&gt;pixiedust_node) (0.6.2) Requirement already satisfied, skipping upgrade: ipython-genutils in c: tools anaconda3 envs fastai2 lib site-packages (from traitlets&gt;=4.2-&gt;ipython-&gt;pixiedust_node) (0.2.0) . Now let&#39;s try activating what we just installed and running some javascript code thru Node. I already have Node installed on my local machine, but if you need it, install Node from here . import pixiedust_node . Pixiedust database opened successfully . Pixiedust version 1.1.18 Pixiedust Node.js %%node print(new Date()); . pixiedust_node 0.2.5 started. Cells starting &#39;%%node&#39; may contain Node.js code. &#34;2020-03-31T11:29:22.434Z&#34; . Wow that&#39;s pretty cool. I will have to read up a little more into the T&amp;C for this, since it seems to be tracking usage in my initial run of the import cell, but the message disappeared when I re-ran it, but I&#39;m not too concerned on this yet since this is just experimentation. . So let&#39;s push a little and see what the limits of this integration can do. I was looking for a WYSIWYG Rich Text Editor to embed in an app, and I came across Quill. I don&#39;t want to invest too much time in getting an app running to see what it does, so let&#39;s see if we can embed the Quill getting started sample code here for a quick experiment with it. I keep forgetting to put %%node at the top of the code cell to run Javascript syntax so hopefully this note here fixes that. . %%node // Remember to use javascript syntax from here forth var htmlString= ` &lt;!-- Include Quill stylesheet --&gt; &lt;link href=&quot;https://cdn.quilljs.com/1.0.0/quill.snow.css&quot; rel=&quot;stylesheet&quot;&gt; &lt;!-- Create the toolbar container --&gt; &lt;div id=&quot;toolbar&quot;&gt; &lt;button class=&quot;ql-bold&quot;&gt;Bold&lt;/button&gt; &lt;button class=&quot;ql-italic&quot;&gt;Italic&lt;/button&gt; &lt;/div&gt; &lt;!-- Create the editor container --&gt; &lt;div id=&quot;editor&quot;&gt; &lt;p&gt;Hello World!&lt;/p&gt; &lt;/div&gt; &lt;!-- Include the Quill library --&gt; &lt;script src=&quot;https://cdn.quilljs.com/1.0.0/quill.js&quot;&gt;&lt;/script&gt; &lt;!-- Initialize Quill editor --&gt; &lt;script type=&quot;text/javascript&quot;&gt; var editor = new Quill(&#39;#editor&#39;, { modules: { toolbar: &#39;#toolbar&#39; }, theme: &#39;snow&#39; }); &lt;/script&gt; ` // console.log(htmlString) html(htmlString) . ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... . Bold Italic Hello World! . Damn, maybe a bit too ambitious a start to think it could do this. Maybe it&#39;s the call to the external JS and Stylesheets. I&#39;ll have to investigate the why of this later. Let me just start with just the simple HTML part of that code and see if this (as uninteresting as it is) will run without error. . %%node var str = ` &lt;!-- Create the editor container --&gt; &lt;div id=&quot;editor&quot;&gt; &lt;p&gt;Hello World!&lt;/p&gt; &lt;p&gt;Some initial &lt;strong&gt;bold&lt;/strong&gt; text&lt;/p&gt; &lt;p&gt;&lt;br&gt;&lt;/p&gt; &lt;/div&gt; ` html(str) . ... ... ... ... ... ... ... . Hello World! . Some initial bold text . . Nothing spectacular, but it is respecting HTML tags so that&#39;s something to note, let&#39;s move on. The documentation for pixiedust_node says I can see what npm packages are available and I can also install npm packages. Let&#39;s take a look what I have, and then try to install another WYSIWYG editor I noted called Froala and see if we fare better here. . %%node npm.list() . Uncaught . %%node npm.install(&#39;froala-editor&#39;) . Uncaught . Ok. So not getting the messages or ease of use I was expecting. Maybe it&#39;s my inexperience with the environment, but I was hoping for better. The pixiedust and pixiedust node combination have some merits, but aren&#39;t quite as glamorous as I hoped they&#39;d be. Let&#39;s do some searching and try another approach. If I come back to doing more here and update the notebook I&#39;ll add a note cell here so the blog post reflects that anything from here is new stuff I added since first published . Alternative approach: ReactJS code sample found in a Github gist . I found a public gist on Github that showed a notebook proporting to run ReactJS code. Let&#39;s give it a try, the code may be copied verbatim since I&#39;m not sure yet what it&#39;s doing so don&#39;t want to break it apart yet, although I might do this in a future review of this. . import json from string import Template from IPython.display import Javascript, display from IPython.core.magic import register_cell_magic display(Javascript(&#39;&#39;&#39; // Load our libraries from a CDN instead of wherever this notebook is hosted. require.config({ paths: { babel: &#39;https://unpkg.com/babel-standalone@6/babel.min&#39;, react: &#39;https://unpkg.com/react@15.3.1/dist/react&#39;, &#39;react-dom&#39;: &#39;https://unpkg.com/react-dom@15.3.1/dist/react-dom&#39; } }) // Hook to call into Python. // Credit to disarticulate for documenting the usage of iopub: // https://gist.github.com/disarticulate/d06069ff3e71cf828e5329beab8cb084 window.python = code =&gt; new Promise((resolve, reject) =&gt; { IPython.notebook.kernel.execute( code, {iopub: {output: data =&gt; resolve(data.content.text)}}, ) }) &#39;&#39;&#39;)) @register_cell_magic def jsx(line, cell): display(Javascript((Template(&#39;&#39;&#39; require([&#39;babel&#39;, &#39;react&#39;, &#39;react-dom&#39;], (Babel, React, ReactDOM) =&gt; { eval(Babel.transform($quoted_script, {presets: [&#39;react&#39;]}).code) }) &#39;&#39;&#39;).substitute(quoted_script=json.dumps(cell))))) . So the first time I ran the above cell I got no errors, but the 2nd time it generated a heap of them. I&#39;m not sure if this is an after-effect of the failed previous experiment, but let&#39;s press on and hope the right bits got compiled as needed. The gist basically says I can set a python variable and then have the JSX declared later use this variable in what it displays. Let&#39;s give this a go using their sample . greeting = &#39;Hello from Python and React!&#39; . %%jsx python(&#39;print(greeting)&#39;).then(greeting =&gt; { ReactDOM.render( &lt;h1&gt;{greeting}&lt;/h1&gt;, element[0], ) }) . Ok it was pretty sweet that the first time I ran the code it rendered, but subsequent running spit out the gob of errors you see above. I wonder if it will work with a more complex bit of code though. I&#39;ll have to dig further and update this post in future with what I find here. There seem to be a few more approaches I can try, and even a few Javascript kernels for Jupyter online to experiment with. . Experiment status:In progress .",
            "url": "https://nissan.github.io/learn-deeplearning-blog/jupyter/javascript/experiments/2020/04/01/Testing-out-Javascript-inside-a-notebook.html",
            "relUrl": "/jupyter/javascript/experiments/2020/04/01/Testing-out-Javascript-inside-a-notebook.html",
            "date": " • Apr 1, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Practice using the Lesson 1 notebook",
            "content": "From Lesson 1 of fastbook as the basis for Lesson 1 of the V4 course currently being run we&#39;re using copies of the notebook code embedded in their new book. So below are my experiments from what I learnt here, starting from scratch but drawing heavily from their textbook code. I run this locally on Windows 10 (I can see Jeremy&#39;s eye rolling if he reads this since he recommended against this for beginners) but in my defense I did do the course last year and had my laptop configured with V1 of Fastai running so thought I&#39;d see where the stress points were, but to keep productive I also run on Google Collab which is honestly much easier. As a caveat, I&#39;m writing this article while running Jupyter Notebook on the Windows 10 environment so if some code looks slightly modified I&#39;ll try to mention explicitly this is a Win10 specific change. Now, on to the experimentation. . First if you&#39;re running this locally make sure you have the &quot;Trusted&quot; button enable for this notebook. . Now we&#39;re going to make sure fastai is installed into my local environment . pip install fastai2 . Requirement already satisfied: fastai2 in c: tools anaconda3 envs fastai2 lib site-packages (0.0.13) Requirement already satisfied: requests in c: tools anaconda3 envs fastai2 lib site-packages (from fastai2) (2.23.0) Requirement already satisfied: pyyaml in c: tools anaconda3 envs fastai2 lib site-packages (from fastai2) (5.3) Requirement already satisfied: spacy in c: tools anaconda3 envs fastai2 lib site-packages (from fastai2) (2.1.8) Requirement already satisfied: pillow in c: tools anaconda3 envs fastai2 lib site-packages (from fastai2) (7.0.0) Requirement already satisfied: fastcore in c: tools anaconda3 envs fastai2 lib site-packages (from fastai2) (0.1.15) Requirement already satisfied: matplotlib in c: tools anaconda3 envs fastai2 lib site-packages (from fastai2) (3.1.3) Requirement already satisfied: fastprogress&gt;=0.1.22 in c: tools anaconda3 envs fastai2 lib site-packages (from fastai2) (0.2.2) Requirement already satisfied: scipy in c: tools anaconda3 envs fastai2 lib site-packages (from fastai2) (1.4.1) Requirement already satisfied: torch&gt;=1.3.0 in c: tools anaconda3 envs fastai2 lib site-packages (from fastai2) (1.4.0) Requirement already satisfied: pandas in c: tools anaconda3 envs fastai2 lib site-packages (from fastai2) (1.0.2) Requirement already satisfied: torchvision&gt;=0.5 in c: tools anaconda3 envs fastai2 lib site-packages (from fastai2) (0.5.0) Requirement already satisfied: scikit-learn in c: tools anaconda3 envs fastai2 lib site-packages (from fastai2) (0.22.2.post1) Requirement already satisfied: certifi&gt;=2017.4.17 in c: tools anaconda3 envs fastai2 lib site-packages (from requests-&gt;fastai2) (2019.11.28) Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in c: tools anaconda3 envs fastai2 lib site-packages (from requests-&gt;fastai2) (3.0.4) Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in c: tools anaconda3 envs fastai2 lib site-packages (from requests-&gt;fastai2) (1.25.8) Requirement already satisfied: idna&lt;3,&gt;=2.5 in c: tools anaconda3 envs fastai2 lib site-packages (from requests-&gt;fastai2) (2.9) Requirement already satisfied: srsly&lt;1.1.0,&gt;=0.0.6 in c: tools anaconda3 envs fastai2 lib site-packages (from spacy-&gt;fastai2) (0.1.0) Requirement already satisfied: preshed&lt;2.1.0,&gt;=2.0.1 in c: tools anaconda3 envs fastai2 lib site-packages (from spacy-&gt;fastai2) (2.0.1) Requirement already satisfied: blis&lt;0.3.0,&gt;=0.2.2 in c: tools anaconda3 envs fastai2 lib site-packages (from spacy-&gt;fastai2) (0.2.4) Requirement already satisfied: thinc&lt;7.1.0,&gt;=7.0.8 in c: tools anaconda3 envs fastai2 lib site-packages (from spacy-&gt;fastai2) (7.0.8) Requirement already satisfied: plac&lt;1.0.0,&gt;=0.9.6 in c: tools anaconda3 envs fastai2 lib site-packages (from spacy-&gt;fastai2) (0.9.6) Requirement already satisfied: cymem&lt;2.1.0,&gt;=2.0.2 in c: tools anaconda3 envs fastai2 lib site-packages (from spacy-&gt;fastai2) (2.0.2) Requirement already satisfied: numpy&gt;=1.15.0 in c: tools anaconda3 envs fastai2 lib site-packages (from spacy-&gt;fastai2) (1.18.1) Requirement already satisfied: wasabi&lt;1.1.0,&gt;=0.2.0 in c: tools anaconda3 envs fastai2 lib site-packages (from spacy-&gt;fastai2) (0.2.2) Requirement already satisfied: murmurhash&lt;1.1.0,&gt;=0.28.0 in c: tools anaconda3 envs fastai2 lib site-packages (from spacy-&gt;fastai2) (1.0.2) Requirement already satisfied: kiwisolver&gt;=1.0.1 in c: tools anaconda3 envs fastai2 lib site-packages (from matplotlib-&gt;fastai2) (1.1.0) Requirement already satisfied: python-dateutil&gt;=2.1 in c: tools anaconda3 envs fastai2 lib site-packages (from matplotlib-&gt;fastai2) (2.8.1) Requirement already satisfied: cycler&gt;=0.10 in c: tools anaconda3 envs fastai2 lib site-packages (from matplotlib-&gt;fastai2) (0.10.0) Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,&gt;=2.0.1 in c: tools anaconda3 envs fastai2 lib site-packages (from matplotlib-&gt;fastai2) (2.4.6) Requirement already satisfied: pytz&gt;=2017.2 in c: tools anaconda3 envs fastai2 lib site-packages (from pandas-&gt;fastai2) (2019.3) Requirement already satisfied: six in c: tools anaconda3 envs fastai2 lib site-packages (from torchvision&gt;=0.5-&gt;fastai2) (1.14.0) Requirement already satisfied: joblib&gt;=0.11 in c: tools anaconda3 envs fastai2 lib site-packages (from scikit-learn-&gt;fastai2) (0.14.1) Requirement already satisfied: tqdm&lt;5.0.0,&gt;=4.10.0 in c: tools anaconda3 envs fastai2 lib site-packages (from thinc&lt;7.1.0,&gt;=7.0.8-&gt;spacy-&gt;fastai2) (4.43.0) Requirement already satisfied: setuptools in c: tools anaconda3 envs fastai2 lib site-packages (from kiwisolver&gt;=1.0.1-&gt;matplotlib-&gt;fastai2) (46.0.0.post20200309) Note: you may need to restart the kernel to use updated packages. . Now in the notebook and the V4 course repo, Jeremy hides alot of the guts of getting things up and running with . from utils import * #this will crash if you run it outside the folder since `utils.py` is in the root folder of the notebooks . ModuleNotFoundError Traceback (most recent call last) &lt;ipython-input-6-f8223ec046d9&gt; in &lt;module&gt; -&gt; 1 from utils import * #this will crash if you run it outside the folder since `utils.py` is in the root folder of the notebooks ModuleNotFoundError: No module named &#39;utils&#39; . But since I like to dig into things I&#39;m going to try to parse the utils.py file and pull out just the pieces we need to get Lesson 1 stuff up and running . from fastai2.vision.all import * . I also want to test my environment to make sure I have a Nvidia GPU and probe for some details on it . import torch torch.cuda.device(0) . &lt;torch.cuda.device at 0x2b2f58b1c48&gt; . torch.cuda.get_device_name(0) . &#39;Quadro P2000&#39; . torch.cuda.is_available() . True . torch.backends.cudnn.enabled . True . import torch.cuda if torch.cuda.is_available(): print(&#39;PyTorch found cuda&#39;) else: print(&#39;PyTorch could not find cuda&#39;) . PyTorch found cuda . There&#39;s a block of code in the notebook that executes a learner on images data of both cats and dogs and their breeds. I&#39;m segmenting that code below and putting notes on each . First he gets the data from the built in URLS object for PETS data which is a simple Amazon S3 storage bucket location containing what looks like either the originally or slightly modified copy of The Oxford-IIIT Pet Dataset . print(URLs.PETS) . https://s3.amazonaws.com/fast-ai-imageclas/oxford-iiit-pet.tgz . So we use a method untar_data to decompress this into our local images folder. In the next block if you uncomment the code and press Shift-Tab 3 (or 4 times for a pop out window) you can see the documentation on the function and the parameters it takes . untar_data #Press `Enter` to see some info or use `Shift+Tab` 3 or 4 times to see more formatted documentation . &lt;function fastai2.data.external.untar_data(url, fname=None, dest=None, c_key=&#39;data&#39;, force_download=False, extract_func=&lt;function file_extract at 0x000002B2F4592948&gt;)&gt; . path = untar_data(URLs.PETS)/&#39;images&#39; . So this had me scratching for awhile when I read the notebook but then in the video Jeremy explained the need for this function. Apparently because it is a mixture of both cats and dogs and their breeds, the way to identify data as being for a cat is to Capitalize The First Letter For Any Cat Breed. So the function below would be reused when classifying data as a Cat before going deeper into identifying its breed. . def is_cat(x): return x[0].isupper() . The ImageDataLoaders function is handy as it has a variety of extensions to make loading from various image sources much easier. FastAI has this concept of a DataLoader that holds the data we&#39;re going to train and validate our model on. Because I&#39;m running this on Windows 10, I had to add an additional parameter of num_workers=0 to the call to make sure it doesn&#39;t crash. For Linux users, you can safely remove this call. . ImageDataLoaders.from_ #press Tab once to see all possible calls . AttributeError Traceback (most recent call last) &lt;ipython-input-17-4e80285fe0f4&gt; in &lt;module&gt; -&gt; 1 ImageDataLoaders.from_ #press Tab once to see all possible calls AttributeError: type object &#39;ImageDataLoaders&#39; has no attribute &#39;from_&#39; . dls = ImageDataLoaders.from_name_func( path, get_image_files(path), valid_pct=0.2, seed=42, label_func=is_cat, item_tfms=Resize(224), num_workers=0) . So now we&#39;re going to call the learner that will train the model to recognise the various cats and dogs breeds in our model using the ResNet34 pre-trained model. A pre-trained model is a very cool concept. Normally to start training a series of weights are chosen at random and over time are changed to better match a specific set of data. These weights are re-usable since basically it lets us jumpstart training a new, related dataset as these pre-trained series of weights are a better starting point than &quot;random&quot; for the new more niche subset of related data. Here we also specifiy the metric we&#39;re using as a measure of accuracy, fastai defines one for us that&#39;s useful, appropriately called error_rate . error_rate # Press Shift+Tab 3 times to see the documentation on this . &lt;function fastai2.metrics.error_rate(inp, targ, axis=-1)&gt; . learn = cnn_learner(dls, resnet34, metrics=error_rate) . Fast.ai V2 also introduced this nice method called fine_tune which basially runs a cycle of training again using a learning rate it has pre-determined as best for training to &quot;fine tune&quot; the model to produce better accuracy. I won&#39;t propose to understand it fully yet, but from what I know it freezes a fixed number of the hidden layers of the pre-trained model, and unfreezes the last few layers so their weights can be changed to better match the niche dataset. The logic is sound as the first set of layers would already be really good at recognising general features common in all images of the superset, but the last few layers can now be fine tuned to match the explicit features in the specific classifications of the niche dataset we are presenting for training in this model. As I learn I may write more about how I understand this function to work and append this post to match what I learn. Note, this step might take some time to execute depending on the speed and memory of the GPU you have running. Google Collab would take about 5 minutes. My local laptop running Windows 10 takes a little longer. . learn.fine_tune(1) . epoch train_loss valid_loss error_rate time . 0 | 0.167801 | 0.024875 | 0.007442 | 07:17 | . epoch train_loss valid_loss error_rate time . 0 | 0.052814 | 0.014244 | 0.006089 | 05:19 | . So now we have a trained model that looks like it has a pretty low error rate and we want to test it with something it hasn&#39;t seen before. This library in the next code block was added early in V3 of the course and is more prominent in V4 and lets you put GUI elements you&#39;re used to in a normal application (like a file uploader) into the notebook. I did a quick web search for a cat, downloaded that file and used it here to test. . from ipywidgets import widgets uploader = widgets.FileUpload() uploader . The next block of code simply looks at the image we loaded, passes it to our model for an evaluation of whether or not it thinks it&#39;s a cat. I&#39;d recommend having both a dog and a cat image available to test on your own . img = PILImage.create(uploader.data[0]) is_cat,_,probs = learn.predict(img) print(f&quot;Is this a cat?: {is_cat}.&quot;) print(f&quot;Probability it&#39;s a cat: {probs[1].item():.6f}&quot;) . Is this a cat?: True. Probability it&#39;s a cat: 1.000000 . And there you go. That simple. You&#39;re now a deep learning practitioner like me so celebrate the accomplishment. Hopefully you feel less like this: . . And more like this: . . Notes from first few minutes Jeremy&#39;s Lesson 2 lecture . Jeremy continued to cover the Chapter 1 notebook from Fastbook in Lesson 2. Appending the notes here to keep them naturally aligned to the Fastbook content for when I get my copy (or you yours) to be able to map it all back more easily . First bring back the code we&#39;re taking a look at . Tip: - Use the fastbook book git repository as well as the course-v4 repository for reference. The fastbook repo should be used as reading material while the course-v4 repo can be used to just see the sample code and experiment to ensure you&#39;re understanding the material . from fastai2.vision.all import * #since I don&#39;t have utils.py here, will just pull the lines from it we need path = untar_data(URLs.PETS)/&#39;images&#39; def is_cat(x): return x[0].isupper() . Now, let&#39;s take a look at the bit he&#39;s exploring for the notes below . dls = ImageDataLoaders.from_name_func( path, get_image_files(path), valid_pct=0.2, seed=42, label_func=is_cat, item_tfms=Resize(224), num_workers=0) #num_workers=0 is needed for Windows only . First thing to note, is we have a labelling function label_func, in this case is_cat(x) which all it does is check the first letter of the file name, because the files are labelled in such a way that an UPPERCASE first letter in the file name indicates it is a cat breed. | . This example code allows us to predict a category, i.e. the label is a category. In this case, our model is a classification modelIf we&#39;re trying to predict a variable number, like an age, or location then this is a regression model . | . What valid_pct=0.2 does in the sample code given is puts aside 20% of the data in training to test the model to see how accurate the model is. This is called a validation set and is useful in detecting overfitting | Overfitting happens when you train the model for too long, or with too little data or with too many parameters, the accuracy of the model starts to go down, since it measures predictions on the validation set and when this value starts to go down, this is a sign of overfitting. | . Looking at cnn_learner(dls, resnet34, metrics=error_rate). This is a learner, which contains your data (dls), a function (resnet34) which we are optimising for our data, and a list of functions (metrics=error_rate) you want executed and printed out after running each epoch. It figures out what are the parameters that best cause the function resnet34 to best match the labels in our data in dls. learner | parameters | epoch - when you look at every image in the training set once. | resnet34 is a particular architecture Resnet that has been shown to be very good at computer vision problems. 34 in resnet34 indicates how many layers there are. The higher numbered versions (resnet50 etc) take more parameters, use more memory, take longer to train, are more likely to overfit but can also create more complex models | architecture | . | . metrics is a function that measures the quality of the predictions using our validation set. error_rate prints out what percent of the training dataset are being incorrectly classified by the model. accuracy is another metric and is calculated as (1 - error_rate) . There is potentially a difference between the metric and the loss, but they are closely related. Attribution to Arthur Samuel&#39;s insight here. . We need a way to measure how well our model is doing so when we change the parameters we cna figure out which set of parameters make that performance measurement get better or worse. The loss is that performance measurement. | . Error rate and accuracy do not indicate if we are getting better or worse if we change our parameters just a little bit, since we may overall be predicting exactly the same number of items correctly, so these are not measures of loss since potentially we could be not predicting as well on the data in the validation set once the parameters are changed, but still well enough to give the labelled output value as the prediction. You generally care most about the metrics, but the program cares about the loss, since this tells it how to update the parameters when running the model against the training data in the next epoch. . We care about how well the model predicts not just with the data we&#39;re training with, but with data it has never seen before. | While we can cheat by developing a model that generates great metrics for our validation set, we can set aside a 3rd set of data, a test set that isn&#39;t used in either training or generating validation metrics for the model, but only used when the entire project is completed. | . Jeremy starts going into fine-tuning, transfer learning, and how using AlexNet example what makes sense intuitively is proven. Parameters vs hyper-parameters. TODO is add notes from here as I go over again this material. .",
            "url": "https://nissan.github.io/learn-deeplearning-blog/fastai/course_v4/2020/03/31/Practice-On-Lessons-From-Lesson-1.html",
            "relUrl": "/fastai/course_v4/2020/03/31/Practice-On-Lessons-From-Lesson-1.html",
            "date": " • Mar 31, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "About me . Hi, my name is Nissan Dookeran and while my day job is as a professional Full Stack Developer/Software Architect, I’m passionate about learning more about Machine Learning, Data Science, AI and Deep Learning. My adventures in Deep Learning are thanks especially to Jeremy Howard’s wonderful Practical Deep Learning for Coders course, of which I’ve been a participating student in 2019 of v3 (videos and other resources of which are available for free) and now the v4 in 2020 which should be available later this year. I’m trying to use FastPages to publish more frequently the things I learn both in his course and otherwise, even though I have another blog or two lying about already that have infrequent updates to them. . Originally I grew up in the sunny Caribbean twin island Republic of Trinidad and Tobago but have traveled the world with extended stays in Barbados, London (U.K), Mexico, Toronto(Canada) and the Boston(USA) before making Brisbane, Australia my present home. You can find out more about my professional career on LinkedIn or connect with me on Twitter(https://www.twitter.com/nissandookeran) or the fastai forums to chat more about any of the Deep Learning posts or notebooks I might publish here. . Attribution . This website is powered by fastpages 1. This site is built with fastpages, An easy to use blogging platform with extra features for Jupyter Notebooks. . . fastpages automates the process of creating blog posts via GitHub Actions, so you don’t have to fuss with conversion scripts. A full list of features can be found on GitHub. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://nissan.github.io/learn-deeplearning-blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

}