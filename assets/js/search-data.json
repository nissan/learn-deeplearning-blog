{
  
    
        "post0": {
            "title": "Title",
            "content": "Practical Deep Learning for Coders V4 Course - My learnings from Lesson 1 . From Lesson 1 of the V4 course currently being run we&#39;re using copies of the notebook code embedded in their new book. So below are my experiments from what I learnt here, starting from scratch but drawing heavily from their textbook code. I run this locally on Windows 10 (I can see Jeremy&#39;s eye rolling if he reads this since he recommended against this for beginners) but in my defense I did do the course last year and had my laptop configured with V1 of Fastai running so thought I&#39;d see where the stress points were, but to keep productive I also run on Google Collab which is honestly much easier. As a caveat, I&#39;m writing this article while running Jupyter Notebook on the Windows 10 environment so if some code looks slightly modified I&#39;ll try to mention explicitly this is a Win10 specific change. Now, on to the experimentation. . First if you&#39;re running this locally make sure you have the &quot;Trusted&quot; button enable for this notebook. . Now we&#39;re going to make sure fastai is installed into my local environment . pip install fastai2 . Requirement already satisfied: fastai2 in c: users nissan.dookeran documents github fastai2 (0.0.16) Requirement already satisfied: fastcore in c: tools anaconda3 envs fastai2 lib site-packages (from fastai2) (0.1.16) Requirement already satisfied: torch&gt;=1.3.0 in c: tools anaconda3 envs fastai2 lib site-packages (from fastai2) (1.4.0) Requirement already satisfied: torchvision&gt;=0.5 in c: tools anaconda3 envs fastai2 lib site-packages (from fastai2) (0.5.0) Requirement already satisfied: matplotlib in c: tools anaconda3 envs fastai2 lib site-packages (from fastai2) (3.1.3) Requirement already satisfied: pandas in c: tools anaconda3 envs fastai2 lib site-packages (from fastai2) (1.0.3) Requirement already satisfied: requests in c: tools anaconda3 envs fastai2 lib site-packages (from fastai2) (2.23.0) Requirement already satisfied: pyyaml in c: tools anaconda3 envs fastai2 lib site-packages (from fastai2) (5.3.1) Requirement already satisfied: fastprogress&gt;=0.1.22 in c: tools anaconda3 envs fastai2 lib site-packages (from fastai2) (0.2.2) Requirement already satisfied: pillow in c: tools anaconda3 envs fastai2 lib site-packages (from fastai2) (7.0.0) Requirement already satisfied: scikit-learn in c: tools anaconda3 envs fastai2 lib site-packages (from fastai2) (0.22.1) Requirement already satisfied: scipy in c: tools anaconda3 envs fastai2 lib site-packages (from fastai2) (1.4.1) Requirement already satisfied: spacy in c: tools anaconda3 envs fastai2 lib site-packages (from fastai2) (2.1.8) Requirement already satisfied: numpy in c: tools anaconda3 envs fastai2 lib site-packages (from fastcore-&gt;fastai2) (1.18.1) Requirement already satisfied: six in c: tools anaconda3 envs fastai2 lib site-packages (from torchvision&gt;=0.5-&gt;fastai2) (1.14.0) Requirement already satisfied: kiwisolver&gt;=1.0.1 in c: tools anaconda3 envs fastai2 lib site-packages (from matplotlib-&gt;fastai2) (1.1.0) Requirement already satisfied: cycler&gt;=0.10 in c: tools anaconda3 envs fastai2 lib site-packages (from matplotlib-&gt;fastai2) (0.10.0) Requirement already satisfied: python-dateutil&gt;=2.1 in c: tools anaconda3 envs fastai2 lib site-packages (from matplotlib-&gt;fastai2) (2.8.1) Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,&gt;=2.0.1 in c: tools anaconda3 envs fastai2 lib site-packages (from matplotlib-&gt;fastai2) (2.4.6) Requirement already satisfied: pytz&gt;=2017.2 in c: tools anaconda3 envs fastai2 lib site-packages (from pandas-&gt;fastai2) (2019.3) Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in c: tools anaconda3 envs fastai2 lib site-packages (from requests-&gt;fastai2) (3.0.4) Requirement already satisfied: idna&lt;3,&gt;=2.5 in c: tools anaconda3 envs fastai2 lib site-packages (from requests-&gt;fastai2) (2.9) Requirement already satisfied: certifi&gt;=2017.4.17 in c: tools anaconda3 envs fastai2 lib site-packages (from requests-&gt;fastai2) (2019.11.28) Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in c: tools anaconda3 envs fastai2 lib site-packages (from requests-&gt;fastai2) (1.25.8) Requirement already satisfied: joblib&gt;=0.11 in c: tools anaconda3 envs fastai2 lib site-packages (from scikit-learn-&gt;fastai2) (0.14.1) Requirement already satisfied: srsly&lt;1.1.0,&gt;=0.0.6 in c: tools anaconda3 envs fastai2 lib site-packages (from spacy-&gt;fastai2) (0.1.0) Requirement already satisfied: murmurhash&lt;1.1.0,&gt;=0.28.0 in c: tools anaconda3 envs fastai2 lib site-packages (from spacy-&gt;fastai2) (1.0.2) Requirement already satisfied: blis&lt;0.3.0,&gt;=0.2.2 in c: tools anaconda3 envs fastai2 lib site-packages (from spacy-&gt;fastai2) (0.2.4) Requirement already satisfied: plac&lt;1.0.0,&gt;=0.9.6 in c: tools anaconda3 envs fastai2 lib site-packages (from spacy-&gt;fastai2) (0.9.6) Requirement already satisfied: thinc&lt;7.1.0,&gt;=7.0.8 in c: tools anaconda3 envs fastai2 lib site-packages (from spacy-&gt;fastai2) (7.0.8) Requirement already satisfied: preshed&lt;2.1.0,&gt;=2.0.1 in c: tools anaconda3 envs fastai2 lib site-packages (from spacy-&gt;fastai2) (2.0.1) Requirement already satisfied: wasabi&lt;1.1.0,&gt;=0.2.0 in c: tools anaconda3 envs fastai2 lib site-packages (from spacy-&gt;fastai2) (0.2.2) Requirement already satisfied: cymem&lt;2.1.0,&gt;=2.0.2 in c: tools anaconda3 envs fastai2 lib site-packages (from spacy-&gt;fastai2) (2.0.2) Requirement already satisfied: setuptools in c: tools anaconda3 envs fastai2 lib site-packages (from kiwisolver&gt;=1.0.1-&gt;matplotlib-&gt;fastai2) (46.1.1.post20200323) Requirement already satisfied: tqdm&lt;5.0.0,&gt;=4.10.0 in c: tools anaconda3 envs fastai2 lib site-packages (from thinc&lt;7.1.0,&gt;=7.0.8-&gt;spacy-&gt;fastai2) (4.43.0) Note: you may need to restart the kernel to use updated packages. . Now in the notebook and the V4 course repo, Jeremy hides alot of the guts of getting things up and running with . But since I like to dig into things I&#39;m going to try to parse the utils.py file and pull out just the pieces we need to get Lesson 1 stuff up and running . from fastai2.vision.all import * . I also want to test my environment to make sure I have a Nvidia GPU and probe for some details on it . import torch torch.cuda.device(0) torch.cuda.get_device_name(0) . &#39;GeForce GTX 1050&#39; . import torch.cuda if torch.cuda.is_available(): print(&#39;PyTorch found cuda&#39;) else: print(&#39;PyTorch could not find cuda&#39;) . PyTorch found cuda . There&#39;s a block of code in the notebook that executes a learner on images data of both cats and dogs and their breeds. I&#39;m segmenting that code below and putting notes on each . First he gets the data from the built in URLS object for PETS data which is a simple Amazon S3 storage bucket location containing what looks like either the originally or slightly modified copy of The Oxford-IIIT Pet Dataset . print(URLs.PETS) . https://s3.amazonaws.com/fast-ai-imageclas/oxford-iiit-pet.tgz . So we use a method untar_data to decompress this into our local images folder. In the next block if you uncomment the code and press Shift-Tab 3 (or 4 times for a pop out window) you can see the documentation on the function and the parameters it takes . untar_data #Press `Enter` to see some info or use `Shift+Tab` 3 or 4 times to see more formatted documentation . path = untar_data(URLs.PETS)/&#39;images&#39; . So this had me scratching for awhile when I read the notebook but then in the video Jeremy explained the need for this function. Apparently because it is a mixture of both cats and dogs and their breeds, the way to identify data as being for a cat is to Capitalize The First Letter For Any Cat Breed. So the function below would be reused when classifying data as a Cat before going deeper into identifying its breed. . def is_cat(x): return x[0].isupper() . The ImageDataLoaders function is handy as it has a variety of extensions to make loading from various image sources much easier. FastAI has this concept of a DataLoader that holds the data we&#39;re going to train and validate our model on. Because I&#39;m running this on Windows 10, I had to add an additional parameter of num_workers=0 to the call to make sure it doesn&#39;t crash. For Linux users, you can safely remove this call. . ImageDataLoaders.from_ #press Tab once to see all possible calls . dls = ImageDataLoaders.from_name_func( path, get_image_files(path), valid_pct=0.2, seed=42, label_func=is_cat, item_tfms=Resize(224), num_workers=0) . So now we&#39;re going to call the learner that will train the model to recognise the various cats and dogs breeds in our model using the ResNet34 pre-trained model. A pre-trained model is a very cool concept. Normally to start training a series of weights are chosen at random and over time are changed to better match a specific set of data. These weights are re-usable since basically it lets us jumpstart training a new, related dataset as these pre-trained series of weights are a better starting point than &quot;random&quot; for the new more niche subset of related data. Here we also specifiy the metric we&#39;re using as a measure of accuracy, fastai defines one for us that&#39;s useful, appropriately called error_rate . error_rate # Press Shift+Tab 3 times to see the documentation on this . learn = cnn_learner(dls, resnet34, metrics=error_rate) . Fast.ai V2 also introduced this nice method called fine_tune which basially runs a cycle of training again using a learning rate it has pre-determined as best for training to &quot;fine tune&quot; the model to produce better accuracy. I won&#39;t propose to understand it fully yet, but from what I know it freezes a fixed number of the hidden layers of the pre-trained model, and unfreezes the last few layers so their weights can be changed to better match the niche dataset. The logic is sound as the first set of layers would already be really good at recognising general features common in all images of the superset, but the last few layers can now be fine tuned to match the explicit features in the specific classifications of the niche dataset we are presenting for training in this model. As I learn I may write more about how I understand this function to work and append this post to match what I learn. Note, this step might take some time to execute depending on the speed and memory of the GPU you have running. Google Collab would take about 5 minutes. My local laptop running Windows 10 takes a little longer. . learn.fine_tune(1) . epoch train_loss valid_loss error_rate time . 0 | 0.171001 | 0.023034 | 0.008119 | 04:04 | . epoch train_loss valid_loss error_rate time . 0 | 0.053063 | 0.024095 | 0.006766 | 03:59 | . So now we have a trained model that looks like it has a pretty low error rate and we want to test it with something it hasn&#39;t seen before. This library in the next code block was added early in V3 of the course and is more prominent in V4 and lets you put GUI elements you&#39;re used to in a normal application (like a file uploader) into the notebook. I did a quick web search for a cat, downloaded that file and used it here to test. . from ipywidgets import widgets uploader = widgets.FileUpload() uploader . The next block of code simply looks at the image we loaded, passes it to our model for an evaluation of whether or not it thinks it&#39;s a cat. I&#39;d recommend having both a dog and a cat image available to test on your own . img = PILImage.create(uploader.data[0]) is_cat,_,probs = learn.predict(img) print(f&quot;Is this a cat?: {is_cat}.&quot;) print(f&quot;Probability it&#39;s a cat: {probs[1].item():.6f}&quot;) . Is this a cat?: True. Probability it&#39;s a cat: 1.000000 . And there you go. That simple. You&#39;re now a deep learning practitioner like me so celebrate the accomplishment. . youtube: https://www.youtube.com/watch?v=535Zy_rf4NU .",
            "url": "https://nissan.github.io/learn-deeplearning-blog/2020/03/31/Practice-On-Lessons-From-Lesson-1.html",
            "relUrl": "/2020/03/31/Practice-On-Lessons-From-Lesson-1.html",
            "date": " • Mar 31, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "About me . Hi, my name is Nissan Dookeran and while my day job is as a professional Full Stack Developer/Software Architect, I’m passionate about learning more about Machine Learning, Data Science, AI and Deep Learning. My adventures in Deep Learning are thanks especially to Jeremy Howard’s wonderful [Practical Deep Learning for Coders] (https://course.fast.ai/) course, of which I’ve been a participating student in 2019 of v3 (videos and other resources of which are available for free) and now the v4 in 2020 which should be available later this year. I’m trying to use FastPages to publish more frequently the things I learn both in his course and otherwise, even though I have another blog or two lying about already that have infrequent updates to them. . Originally I grew up in the sunny Caribbean twin island Republic of Trinidad and Tobago but have traveled the world with extended stays in Barbados, London (U.K), Mexico, Toronto(Canada) and the Boston(USA) before making Brisbane, Australia my present home. You can find out more about my professional career on LinkedIn or connect with me on Twitter(https://www.twitter.com/nissandookeran) or the fastai forums to chat more about any of the Deep Learning posts or notebooks I might publish here. . Attribution . This website is powered by fastpages 1. This site is built with fastpages, An easy to use blogging platform with extra features for Jupyter Notebooks. . . fastpages automates the process of creating blog posts via GitHub Actions, so you don’t have to fuss with conversion scripts. A full list of features can be found on GitHub. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://nissan.github.io/learn-deeplearning-blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

}