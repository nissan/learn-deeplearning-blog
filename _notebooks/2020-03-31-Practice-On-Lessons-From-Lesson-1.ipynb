{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice using the Lesson 1 notebook\n",
    "> Notes diving deeper into the Lesson 1 notebook from V4 of the Practical Deep Learning for Coders course\n",
    "\n",
    "- toc:true\n",
    "- branch: master\n",
    "- badges: true\n",
    "- author: Nissan Dookeran\n",
    "- categories: [fastai, course_v4]\n",
    "- show_tags: true\n",
    "- comments: true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Lesson 1 of the V4 course currently being run we're using copies of the notebook code embedded in their new book. So below are my experiments from what I learnt here, starting from scratch but drawing heavily from their textbook code. I run this locally on Windows 10 (I can see Jeremy's eye rolling if he reads this since he recommended against this for beginners) but in my defense I did do the course last year and had my laptop configured with V1 of Fastai running so thought I'd see where the stress points were, but to keep productive I also run on Google Collab which is honestly much easier. As a caveat, I'm writing this article while running Jupyter Notebook on the Windows 10 environment so if some code looks slightly modified I'll try to mention explicitly this is a Win10 specific change. Now, on to the experimentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First if you're running this locally make sure you have the \"Trusted\" button enable for this notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're going to make sure fastai is installed into my local environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastai2 in c:\\users\\nissan.dookeran\\documents\\github\\fastai2 (0.0.16)\n",
      "Requirement already satisfied: fastcore in c:\\tools\\anaconda3\\envs\\fastai2\\lib\\site-packages (from fastai2) (0.1.16)\n",
      "Requirement already satisfied: torch>=1.3.0 in c:\\tools\\anaconda3\\envs\\fastai2\\lib\\site-packages (from fastai2) (1.4.0)\n",
      "Requirement already satisfied: torchvision>=0.5 in c:\\tools\\anaconda3\\envs\\fastai2\\lib\\site-packages (from fastai2) (0.5.0)\n",
      "Requirement already satisfied: matplotlib in c:\\tools\\anaconda3\\envs\\fastai2\\lib\\site-packages (from fastai2) (3.1.3)\n",
      "Requirement already satisfied: pandas in c:\\tools\\anaconda3\\envs\\fastai2\\lib\\site-packages (from fastai2) (1.0.3)\n",
      "Requirement already satisfied: requests in c:\\tools\\anaconda3\\envs\\fastai2\\lib\\site-packages (from fastai2) (2.23.0)\n",
      "Requirement already satisfied: pyyaml in c:\\tools\\anaconda3\\envs\\fastai2\\lib\\site-packages (from fastai2) (5.3.1)\n",
      "Requirement already satisfied: fastprogress>=0.1.22 in c:\\tools\\anaconda3\\envs\\fastai2\\lib\\site-packages (from fastai2) (0.2.2)\n",
      "Requirement already satisfied: pillow in c:\\tools\\anaconda3\\envs\\fastai2\\lib\\site-packages (from fastai2) (7.0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\tools\\anaconda3\\envs\\fastai2\\lib\\site-packages (from fastai2) (0.22.1)\n",
      "Requirement already satisfied: scipy in c:\\tools\\anaconda3\\envs\\fastai2\\lib\\site-packages (from fastai2) (1.4.1)\n",
      "Requirement already satisfied: spacy in c:\\tools\\anaconda3\\envs\\fastai2\\lib\\site-packages (from fastai2) (2.1.8)\n",
      "Requirement already satisfied: numpy in c:\\tools\\anaconda3\\envs\\fastai2\\lib\\site-packages (from fastcore->fastai2) (1.18.1)\n",
      "Requirement already satisfied: six in c:\\tools\\anaconda3\\envs\\fastai2\\lib\\site-packages (from torchvision>=0.5->fastai2) (1.14.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\tools\\anaconda3\\envs\\fastai2\\lib\\site-packages (from matplotlib->fastai2) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\tools\\anaconda3\\envs\\fastai2\\lib\\site-packages (from matplotlib->fastai2) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\tools\\anaconda3\\envs\\fastai2\\lib\\site-packages (from matplotlib->fastai2) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\tools\\anaconda3\\envs\\fastai2\\lib\\site-packages (from matplotlib->fastai2) (2.4.6)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\tools\\anaconda3\\envs\\fastai2\\lib\\site-packages (from pandas->fastai2) (2019.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\tools\\anaconda3\\envs\\fastai2\\lib\\site-packages (from requests->fastai2) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\tools\\anaconda3\\envs\\fastai2\\lib\\site-packages (from requests->fastai2) (2.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\tools\\anaconda3\\envs\\fastai2\\lib\\site-packages (from requests->fastai2) (2019.11.28)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\tools\\anaconda3\\envs\\fastai2\\lib\\site-packages (from requests->fastai2) (1.25.8)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\tools\\anaconda3\\envs\\fastai2\\lib\\site-packages (from scikit-learn->fastai2) (0.14.1)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.0.6 in c:\\tools\\anaconda3\\envs\\fastai2\\lib\\site-packages (from spacy->fastai2) (0.1.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\tools\\anaconda3\\envs\\fastai2\\lib\\site-packages (from spacy->fastai2) (1.0.2)\n",
      "Requirement already satisfied: blis<0.3.0,>=0.2.2 in c:\\tools\\anaconda3\\envs\\fastai2\\lib\\site-packages (from spacy->fastai2) (0.2.4)\n",
      "Requirement already satisfied: plac<1.0.0,>=0.9.6 in c:\\tools\\anaconda3\\envs\\fastai2\\lib\\site-packages (from spacy->fastai2) (0.9.6)\n",
      "Requirement already satisfied: thinc<7.1.0,>=7.0.8 in c:\\tools\\anaconda3\\envs\\fastai2\\lib\\site-packages (from spacy->fastai2) (7.0.8)\n",
      "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in c:\\tools\\anaconda3\\envs\\fastai2\\lib\\site-packages (from spacy->fastai2) (2.0.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in c:\\tools\\anaconda3\\envs\\fastai2\\lib\\site-packages (from spacy->fastai2) (0.2.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\tools\\anaconda3\\envs\\fastai2\\lib\\site-packages (from spacy->fastai2) (2.0.2)\n",
      "Requirement already satisfied: setuptools in c:\\tools\\anaconda3\\envs\\fastai2\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib->fastai2) (46.1.1.post20200323)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in c:\\tools\\anaconda3\\envs\\fastai2\\lib\\site-packages (from thinc<7.1.0,>=7.0.8->spacy->fastai2) (4.43.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install fastai2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now in the notebook and the V4 course repo, Jeremy hides alot of the guts of getting things up and running with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import * #this will crash if you run it outside the folder since `utils.py` is in the root folder of the notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But since I like to dig into things I'm going to try to parse the `utils.py` file and pull out just the pieces we need to get Lesson 1 stuff up and running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai2.vision.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also want to test my environment to make sure I have a Nvidia GPU and probe for some details on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce GTX 1050'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.device(0)\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch found cuda\n"
     ]
    }
   ],
   "source": [
    "import torch.cuda\n",
    "if torch.cuda.is_available():\n",
    "    print('PyTorch found cuda')\n",
    "else:\n",
    "    print('PyTorch could not find cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a block of code in the notebook that executes a learner on images data of both cats and dogs and their breeds. I'm segmenting that code below and putting notes on each"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First he gets the data from the built in `URLS` object for `PETS` data which is a simple Amazon S3 storage bucket location containing what looks like either the originally or slightly modified copy of [The Oxford-IIIT Pet Dataset](https://www.robots.ox.ac.uk/~vgg/data/pets/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://s3.amazonaws.com/fast-ai-imageclas/oxford-iiit-pet.tgz\n"
     ]
    }
   ],
   "source": [
    "print(URLs.PETS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we use a method `untar_data` to decompress this into our local `images` folder. In the next block if you uncomment the code and press `Shift-Tab` 3 (or 4 times for a pop out window) you can see the documentation on the function and the parameters it takes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "untar_data #Press `Enter` to see some info or use `Shift+Tab` 3 or 4 times to see more formatted documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.PETS)/'images'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this had me scratching for awhile when I read the notebook but then in the video Jeremy explained the need for this function. Apparently because it is a mixture of both cats and dogs and their breeds, the way to identify data as being for a cat is to Capitalize The First Letter For Any Cat Breed. So the function below would be reused when classifying data as a Cat before going deeper into identifying its breed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_cat(x): return x[0].isupper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ImageDataLoaders` function is handy as it has a variety of extensions to make loading from various image sources much easier. FastAI has this concept of a `DataLoader` that holds the data we're going to train and validate our model on. Because I'm running this on Windows 10, I had to add an additional parameter of `num_workers=0` to the call to make sure it doesn't crash. For Linux users, you can safely remove this call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImageDataLoaders.from_ #press Tab once to see all possible calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = ImageDataLoaders.from_name_func(\n",
    "    path, get_image_files(path), valid_pct=0.2, seed=42,\n",
    "    label_func=is_cat, item_tfms=Resize(224), num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we're going to call the learner that will train the model to recognise the various cats and dogs breeds in our model using the [ResNet34](https://arxiv.org/abs/1512.03385) pre-trained model. A pre-trained model is a very cool concept. Normally to start training a series of weights are chosen at random and over time are changed to better match a specific set of data. These weights are re-usable since basically it lets us jumpstart training a new, related dataset as these pre-trained series of weights are a better starting point than \"random\" for the new more niche subset of related data. Here we also specifiy the metric we're using as a measure of accuracy, fastai defines one for us that's useful, appropriately called `error_rate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rate # Press Shift+Tab 3 times to see the documentation on this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(dls, resnet34, metrics=error_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fast.ai V2 also introduced this nice method called `fine_tune` which basially runs a cycle of training again using a learning rate it has pre-determined as best for training to \"fine tune\" the model to produce better accuracy. I won't propose to understand it fully yet, but from what I know it freezes a fixed number of the hidden layers of the pre-trained model, and unfreezes the last few layers so their weights can be changed to better match the niche dataset. The logic is sound as the first set of layers would already be really good at recognising general features common in all images of the superset, but the last few layers can now be fine tuned to match the explicit features in the specific classifications of the niche dataset we are presenting for training in this model. As I learn I may write more about how I understand this function to work and append this post to match what I learn. Note, this step might take some time to execute depending on the speed and memory of the GPU you have running. Google Collab would take about 5 minutes. My local laptop running Windows 10 takes a little longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.171001</td>\n",
       "      <td>0.023034</td>\n",
       "      <td>0.008119</td>\n",
       "      <td>04:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.053063</td>\n",
       "      <td>0.024095</td>\n",
       "      <td>0.006766</td>\n",
       "      <td>03:59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fine_tune(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have a trained model that looks like it has a pretty low error rate and we want to test it with something it hasn't seen before. This library in the next code block was added early in V3 of the course and is more prominent in V4 and lets you put GUI elements you're used to in a normal application (like a file uploader) into the notebook. I did a quick web search for a cat, downloaded that file and used it here to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "601374617753497db5805fceb0790573",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value={}, description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import widgets\n",
    "uploader = widgets.FileUpload()\n",
    "uploader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next block of code simply looks at the image we loaded, passes it to our model for an evaluation of whether or not it thinks it's a cat. I'd recommend having both a dog and a cat image available to test on your own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is this a cat?: True.\n",
      "Probability it's a cat: 1.000000\n"
     ]
    }
   ],
   "source": [
    "img = PILImage.create(uploader.data[0])\n",
    "is_cat,_,probs = learn.predict(img)\n",
    "print(f\"Is this a cat?: {is_cat}.\")\n",
    "print(f\"Probability it's a cat: {probs[1].item():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And there you go. That simple. You're now a deep learning practitioner like me so celebrate the accomplishment.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> youtube: https://www.youtube.com/watch?v=535Zy_rf4NU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
